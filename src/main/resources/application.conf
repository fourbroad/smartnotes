akka {
#  loggers = ["akka.event.slf4j.Slf4jLogger"]
#  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
#  logger-startup-timeout = 30s
  loglevel = "DEBUG"
  stdout-loglevel = "DEBUG"
  
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2551
    }
  }

  cluster {
    seed-nodes = ["akka.tcp://SmartNotes@127.0.0.1:2551"]
    roles = ["nameService"]
    auto-down-unreachable-after = 10s
    metrics.enabled = off
    distributed-data.durable{
      keys = ["*"]
      lmdb.dir = "ddata"
    }
  }

  extensions = [akka.persistence.Persistence]
  
  persistence {
    journal {
      plugin = "akka.persistence.journal.leveldb"
      leveldb.native = false
      leveldb.dir = "target/journal"
      
      auto-start-journals = ["akka.persistence.journal.leveldb"]
    }

    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
      auto-start-snapshot-stores = ["akka.persistence.snapshot-store.local"]
      local.dir = "target/snapshots"
    }
 
    elasticsearch-snapshot-store {
      class = "com.zxtx.persistence.ElasticSearchSnapshotStore"
      plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"
    }
       
    elasticsearch.journal{
        class = "com.zxtx.persistence.ElasticSearchJournal"
        event-adapters {
          event = "com.zxtx.actors.DocumentEventAdapter"
        }
        event-adapter-bindings {
          "com.zxtx.actors.DocumentActor$DocumentCreated" = event
          "com.zxtx.actors.DocumentActor$DocumentReplaced" = event
          "com.zxtx.actors.DocumentActor$DocumentPatched" = event
          "com.zxtx.actors.DocumentActor$DocumentDeleted" = event
          "com.zxtx.actors.CollectionActor$CollectionCreated" = event
          "com.zxtx.actors.CollectionActor$CollectionReplaced" = event
          "com.zxtx.actors.CollectionActor$CollectionPatched" = event
          "com.zxtx.actors.CollectionActor$CollectionDeleted" = event
          "com.zxtx.actors.DomainActor$DomainCreated" = event
          "com.zxtx.actors.DomainActor$DomainReplaced" = event
          "com.zxtx.actors.DomainActor$DomainPatched" = event
          "com.zxtx.actors.DomainActor$DomainDeleted" = event
          "com.zxtx.actors.DomainActor$DomainJoined" = event
          "com.zxtx.actors.DomainActor$DomainQuited" = event
          "com.zxtx.actors.UserActor$UserCreated" = event
          "com.zxtx.actors.UserActor$UserReplaced" = event
          "com.zxtx.actors.UserActor$UserPatched" = event
          "com.zxtx.actors.UserActor$UserDeleted" = event
          "com.zxtx.actors.UserActor$PasswordReseted" = event
          "com.zxtx.actors.ACL$ACLSet" = event
          "com.zxtx.actors.ACL$EventACLSet" = event
          "spray.json.JsValue" = event
        }
    }
    
    query.journal.elasticsearch {
        # Implementation class of the ElasticSearch ReadJournalProvider
        class = "com.zxtx.persistence.ElasticSearchReadJournalProvider"
        
        # Absolute path to the write journal plugin configuration entry that this
        # query journal will connect to. That must be a LeveldbJournal or SharedLeveldbJournal.
        # If undefined (or "") it will connect to the default journal as specified by the
        # akka.persistence.journal.plugin property.
        write-plugin = "akka.persistence.elasticsearch.journal"
        
        # How many events to fetch in one query (replay) and keep buffered until they
        # are delivered downstreams.
        max-buffer-size = 100
    }
  }
}

domain {
  root-domain = "localhost"
  cache-key = "cache-smartnotes"
  
  administrator {
      name = "administrator"
      password = "!QAZ)OKM"
  }
}

name_service {
  # waiting for name to be registered.
  timeout = 10s
}